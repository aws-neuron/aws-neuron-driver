/*
 * Copyright 2021, Amazon.com, Inc. or its affiliates. All Rights Reserved
 */

#ifndef NEURON_DRIVER_SHARED_H
#define NEURON_DRIVER_SHARED_H

#include <linux/types.h>

enum neuron_driver_feature_flag {
	NEURON_DRIVER_FEATURE_DMABUF = 1ull <<  0, 
	NEURON_DRIVER_FEATURE_ASYNC_DMA = 1ull <<  1, 
	NEURON_DRIVER_FEATURE_BATCH_DMAQ_INIT = 1ull <<  2, 
	NEURON_DRIVER_FEATURE_BIG_CORE_MAPS   = 1ull <<  3, 
	NEURON_DRIVER_FEATURE_MEM_ALLOC_TYPE  = 1ull <<  4,
	NEURON_DRIVER_FEATURE_HBM_SCRUB = 1ull << 5,
	NEURON_DRIVER_FEATURE_MEM_ALLOC64 = 1ull << 6,
	NEURON_DRIVER_FEATURE_CONTIGUOUS_SCRATCHPAD = 1ull << 7,
};

// FIXME  this should be more generic - like node type.
enum {
	NEURON_POD_TYPE_NONE = 0,
	NEURON_POD_TYPE_P2P,
	NEURON_POD_TYPE_SWITCH
};

enum {
	NEURON_POD_E_STATE_NOT_STARTED= 0,
	NEURON_POD_E_STATE_IN_PROGRESS,
	NEURON_POD_E_STATE_ULTRASERVER,
	NEURON_POD_E_STATE_FAILED,				// TODO we currently don't discriminate between failed and single node (todo for diagnostic/debug purposes)
	NEURON_POD_E_STATE_SINGLE_NODE,
};

enum neuron_pod_ctrl_req {
	NEURON_NPE_POD_CTRL_REQ_POD = 0,  		 // request pod state to pod (on-demand election request)
	NEURON_NPE_POD_CTRL_REQ_SINGLE_NODE = 1, // request pod state to single node
	NEURON_NPE_POD_CTRL_REQ_KILL = 2,		 // request to kill the election
	NEURON_NPE_POD_CTRL_SET_MODE = 3,		 // request to ultraserver mode
};

enum neuron_ultraserver_mode {
	NEURON_ULTRASERVER_MODE_UNSET = 0,  	 // no configuration set
	NEURON_ULTRASERVER_MODE_X4 = 1,  		 // 4 node US configuration
	NEURON_ULTRASERVER_MODE_X2H = 2,  		 // 2 node US configuration using horizontal links 
	NEURON_ULTRASERVER_MODE_X2V = 3,  		 // 2 node US configuration using vertical links 
	NEURON_ULTRASERVER_MODE_X1 = 4,  		 // 1 node US configuration (standalone)
};

#define NEURON_NC_MAP_DEVICE (0xffffffff)

enum neuron_dma_queue_type {
	NEURON_DMA_QUEUE_TYPE_TX = 0, // transmit queue
	NEURON_DMA_QUEUE_TYPE_RX, // receive queue
	NEURON_DMA_QUEUE_TYPE_COMPLETION, // completion queue
};

enum neuron_cinit_state {
	NEURON_CINIT_STATE_STARTED = 1, // Core Init is initiated
	NEURON_CINIT_STATE_COMPLETED, // Core Init is completed successfully
	NEURON_CINIT_STATE_INVALID // Core Init is not valid
};


struct neuron_dma_eng_state {
	__u32 revision_id; // revision id
	__u32 max_queues; // maximum queues supported
	__u32 num_queues; // number of queues configured
	__u32 tx_state; // Tx statue
	__u32 rx_state; // Rx state
};

struct neuron_dma_queue_state {
	__u32 hw_status; // hardware status
	__u32 sw_status; // software status
	__u64 base_addr; // base address of the queue
	__u32 length; // size of the queue
	__u32 head_pointer; // hardware pointer index
	__u32 tail_pointer; // software pointer index
	__u64 completion_base_addr; // completion queue base address
	__u32 completion_head; // completion head
};

enum neuron_dma_h2t_ctx_handle_type {
	NEURON_DMA_H2T_CTX_HANDLE_NONE   = -1,  // no handle - used as prev handle to start an async dma
	NEURON_DMA_H2T_CTX_HANDLE_SYNC   =  0,  // handle for doing synchronous DMA
	NEURON_DMA_H2T_CTX_HANDLE_ASYNC1 =  1,  // first of two async handles
	NEURON_DMA_H2T_CTX_HANDLE_ASYNC2 =  2,  // second of two async handles
	NEURON_DMA_H2T_CTX_HANDLE_CNT    =  3   // number of dma 
};


/*
 * NOTE: In runtime version 5, this enum was passed in as a bool instead -
 * true if top_sp and false if NC. Match the enum values to the bool to
 * maintain compatibility with older runtime. Do not change these values
 * until the min compatibility version is updated to >=6.
 */
enum NQ_DEVICE_TYPE {
    NQ_DEVICE_TYPE_NEURON_CORE = 0,
    NQ_DEVICE_TYPE_TOPSP,
    NQ_DEVICE_TYPE_MAX
};

enum NQ_TYPE {
	NQ_TYPE_TRACE = 0, /**< Implicit notifications generated during execution. */
	NQ_TYPE_NOTIFY, /**< Explicit notifications generated by NOTIFY instruction */
	NQ_TYPE_EVENT, /**< Notifications triggered by event set/clear operations. */
	NQ_TYPE_ERROR, /**< Notifications triggered by an error condition. */
	NQ_TYPE_TRACE_DMA, /**< Implicit notifications generated by DMA transfers.*/
	NQ_TYPE_THROTTLE,   /**< Notifications triggered by HAM throttling activity. */
	NQ_TYPE_MAX
};

/**
 * memory mapping enums for selecting what bar0 resources to map.
 * Bar0 mmapping is restricted to a limited set of regions.
 * Resources are selected by block type, block id and resource within the block.
 * TPB 1 State buffer, for example - where type is TPB, block id is 1 and 
 * resource is state buffer.
 * NEURON_DM_RESOURCE_ALL resource mapping is restricted to read only.
 *
 */
enum neuron_dm_block_type {
   NEURON_DM_BLOCK_INVALID = -1,  // invalid - tag last entry in the table
   NEURON_DM_BLOCK_TPB     =  0,
   NEURON_DM_BLOCK_TOPSP   =  1,
   NEURON_DM_BLOCK_HBM     =  2
};

enum neuron_dm_resource_type {
   NEURON_DM_RESOURCE_SEMAPHORE = 0,  // resource to mmap is semaphore region
   NEURON_DM_RESOURCE_ALL = 1,        // resource to mmap is the entire block (read only). Only available for TOPSP
   NEURON_DM_RESOURCE_SBUF = 2,       // resource to mmap is state buffer
   NEURON_DM_RESOURCE_DMEM = 3	      // resource to mmap is device memory
};

struct neuron_uuid {
	__u8 value[32];
};

#define NEURON_MAX_PROCESS_PER_DEVICE 16 // 2 per core (arbitrary but needs to small number for fast lookup)

#define APP_INFO_PID_NC_LOCK_INFO	(1)
#define APP_INFO_PID_MEM_USAGE		(1 << 1)
#define APP_INFO_ALL			(0xF)

#define APP_INFO_MAX_MODELS_PER_DEVICE	(4)
#define NDS_INVALID_ID (-1)

struct neuron_app_info {
	__s32 pid;							// PID of this app
	__u8 nc_lock_map;						// NCs which are locked by it (one bit set for each locked NC)
	struct neuron_uuid uuid_data[APP_INFO_MAX_MODELS_PER_DEVICE];	// UUIDs running for this app for each neuroncore
	size_t host_mem_size;						// Amount of host memory used by this PID
	size_t device_mem_size;						// Amount of device memory used by this PID
};

typedef union nmetric_version {
	struct {
		__u64 build_num : 32;
		__u64 minor_ver : 8;
		__u64 major_ver : 8;
		__u64 reserved : 16;
	};
	__u64 all;
} nmetric_version_t;

struct neuron_ioctl_mem_chunk_info {
	__u64 pa;
	__u64 size;
	__u32 mem_type;
};

// Max number of entries this version of the driver
// will ever give back to the user
#define NEURON_NC_MAP_MAX_ENTRIES 128
enum neuron_ioctl_nc_mapping_type {
    NEURON_IOCTL_NC_MAPPING_TYPE_V0 = 0,           // seng swap mapping
};
struct neuron_ioctl_nc_map_entry {
    __u32 device_id;
    __u32 device_nc_idx;
};
struct neuron_ioctl_nc_map {
    __u32 num_entries;
    struct neuron_ioctl_nc_map_entry mappings[];
};

/*
 * Memory allocation categories for sysfs counters
*/
typedef enum {
	NEURON_MEMALLOC_TYPE_UNKNOWN_HOST, // only for old runtimes, do not use elsewhere
	NEURON_MEMALLOC_TYPE_CODE_HOST,
	NEURON_MEMALLOC_TYPE_TENSORS_HOST,
	NEURON_MEMALLOC_TYPE_CONSTANTS_HOST,
	NEURON_MEMALLOC_TYPE_MISC_HOST,
	NEURON_MEMALLOC_TYPE_NCDEV_HOST,
	NEURON_MEMALLOC_TYPE_NOTIFICATION_HOST,

	NEURON_MEMALLOC_TYPE_UNKNOWN_DEVICE, // only for old runtimes, do not use elsewhere
	NEURON_MEMALLOC_TYPE_CODE_DEVICE,
	NEURON_MEMALLOC_TYPE_TENSORS_DEVICE,
	NEURON_MEMALLOC_TYPE_CONSTANTS_DEVICE,
	NEURON_MEMALLOC_TYPE_SCRATCHPAD_DEVICE,
	NEURON_MEMALLOC_TYPE_MISC_DEVICE,
	NEURON_MEMALLOC_TYPE_NCDEV_DEVICE,
	NEURON_MEMALLOC_TYPE_COLLECTIVES_DEVICE,
	NEURON_MEMALLOC_TYPE_SCRATCHPAD_NONSHARED_DEVICE,
	NEURON_MEMALLOC_TYPE_NOTIFICATION_DEVICE,

	NEURON_MEMALLOC_TYPE_DMA_RINGS_HOST,
	NEURON_MEMALLOC_TYPE_DMA_RINGS_DEVICE,

	NEURON_MEMALLOC_TYPE_CONTIGUOUS_SCRATCHPAD_DEVICE, // uses same sysfs counter as NEURON_MEMALLOC_TYPE_SCRATCHPAD_DEVICE

	NEURON_MEMALLOC_TYPE_MAX
} mem_alloc_category_t;

/*
 * NDS stats
 * Note: 
 * 	To add a new counter type inside the enum, 
 * 		1. you need to manually decrease NDS_ND_COUNTER_RESERVED or NDS_NC_COUNTER_RESERVED by 1
 * 		2. you need to update NDS_ND_COUNTER_COUNT or NDS_NC_COUNTER_COUNT
 * 	To prevent compatability issues, you need to always append the new counter type to the end of the enum
 */
#define NDS_ND_COUNTER_RESERVED 18

// Device counter types
enum {
	NDS_ND_COUNTER_RUNTIME_VERSION,
	NDS_ND_COUNTER_FRAMEWORK_VERSION,
	NDS_ND_COUNTER_FAL_VERSION,
	NDS_ND_COUNTER_FEATURE_BITMAP,
	NDS_ND_COUNTER_MIN_NEFF_VERSION,
	NDS_ND_COUNTER_MAX_NEFF_VERSION,

	// memory usage counters
	NDS_ND_COUNTER_MEM_USAGE_CODE_HOST,
	NDS_ND_COUNTER_MEM_USAGE_TENSORS_HOST,
	NDS_ND_COUNTER_MEM_USAGE_CONSTANTS_HOST,
	NDS_ND_COUNTER_MEM_USAGE_SCRATCHPAD_HOST,
	NDS_ND_COUNTER_MEM_USAGE_MISC_HOST,

	NDS_ND_COUNTER_DYNAMIC_SYSFS_METRIC_BITMAP,

	NDS_ND_COUNTER_DEVICE_CLUSTER_ID,

	NDS_ND_COUNTER_COUNT = NDS_ND_COUNTER_DEVICE_CLUSTER_ID + NDS_ND_COUNTER_RESERVED + 1
};

#define NDS_NC_COUNTER_RESERVED 0

// Neuroncore counter types
enum {
	NDS_NC_COUNTER_TIME_IN_USE = 0,

	NDS_NC_COUNTER_INFER_COMPLETED,
	NDS_NC_COUNTER_INFER_COMPLETED_WITH_ERR,
	NDS_NC_COUNTER_INFER_COMPLETED_WITH_NUM_ERR,
	NDS_NC_COUNTER_INFER_TIMED_OUT,
	NDS_NC_COUNTER_INFER_INCORRECT_INPUT,
	NDS_NC_COUNTER_INFER_FAILED_TO_QUEUE,

	// these must be in this specifc order
	// runtime assumes these are offset by
	// error code
	NDS_NC_COUNTER_ERR_GENERIC,
	NDS_NC_COUNTER_ERR_NUMERICAL,
	NDS_NC_COUNTER_ERR_MODEL,
	NDS_NC_COUNTER_ERR_TRANSIENT,
	NDS_NC_COUNTER_ERR_HW,
	NDS_NC_COUNTER_ERR_RT,

	NDS_NC_COUNTER_LATENCY_DEVICE,
	NDS_NC_COUNTER_LATENCY_TOTAL,
	NDS_NC_COUNTER_NC_TIME,

	// these are new counters
	// these shall be placed at the
	// end so there offsets are always
	// greater than old counters
	// This will ensure
	// new runtime + old driver will
	// write to reserved setions and not
	// break anything
	NDS_NC_COUNTER_GENERIC_FAIL,
	NDS_NC_COUNTER_ERR_RESOURCE,
	NDS_NC_COUNTER_ERR_RESOURCE_NC,
	NDS_NC_COUNTER_ERR_INVALID,
	NDS_NC_COUNTER_ERR_UNSUPPORTED_NEFF_VERSION,

	NDS_NC_COUNTER_CC_TIME,

	NDS_NC_COUNTER_MEM_USAGE_CODE_DEVICE,
	NDS_NC_COUNTER_MEM_USAGE_TENSORS_DEVICE,
	NDS_NC_COUNTER_MEM_USAGE_CONSTANTS_DEVICE,
	NDS_NC_COUNTER_MEM_USAGE_SCRATCHPAD_DEVICE,
	NDS_NC_COUNTER_MEM_USAGE_MISC_DEVICE,

	NDS_NC_COUNTER_MODEL_LOAD_COUNT,
	NDS_NC_COUNTER_INFERENCE_COUNT,

	NDS_NC_COUNTER_MAC_COUNT,

	NDS_NC_COUNTER_OOB,

	NDS_NC_COUNTER_COUNT = NDS_NC_COUNTER_OOB + NDS_NC_COUNTER_RESERVED + 1
};

#define NDS_MAX_NEURONCORE_COUNT     (4)
#define NDS_EXT_MAX_NEURONCORE_COUNT (12)

// Additional NC storage
// | NDS_EXT_NC_COUNTER_COUNT | ... | NDS_EXT_NC_COUNTER_COUNT | (x NDS_MAX_NEURONCORE_COUNT) - this will only store the 'overflow' from the original counters
// | NDS_NC_COUNTER_COUNT + NDS_EXT_NC_COUNTER_COUNT | ... (x NDS_EXT_MAX_NEURONCORE_COUNT)   - this will store complete data for additional NCs (up to a max of 16)
#define NDS_EXT_NC_COUNTER_ADDED_RESERVED 54
// Index of NC counter extensions start at NDS_NC_COUNTER_COUNT not at 0
enum {
	NDS_EXT_NC_COUNTER_HW_ERR_COLLECTIVES = NDS_NC_COUNTER_COUNT,
	NDS_EXT_NC_COUNTER_HW_ERR_HBM_UE,
	NDS_EXT_NC_COUNTER_HW_ERR_NC_UE,
	NDS_EXT_NC_COUNTER_HW_ERR_DMA_ABORT,
	NDS_EXT_NC_COUNTER_ERR_SW_NQ_OVERFLOW,
	NDS_EXT_NC_COUNTER_ERR_SW_SEMAPHORE_ERROR,
	NDS_EXT_NC_COUNTER_ERR_SW_EVENT_ERROR,
	NDS_EXT_NC_COUNTER_ERR_SW_PSUM_COLLISION,
	NDS_EXT_NC_COUNTER_ERR_SW_SEQUENCER_FATAL,
	NDS_EXT_NC_COUNTER_HW_ERR_REPAIRABLE_HBM_UE,
	NDS_EXT_NC_COUNTER_LAST,
	NDS_EXT_NC_COUNTER_COUNT =  NDS_EXT_NC_COUNTER_LAST - NDS_NC_COUNTER_COUNT + NDS_EXT_NC_COUNTER_ADDED_RESERVED
};

#define NDS_TOTAL_NC_COUNTER_COUNT (NDS_NC_COUNTER_COUNT + NDS_EXT_NC_COUNTER_COUNT) // 31 original + 64 extended = 95 counters

typedef struct nds_header {
	char signature[4];      // Fixed signature: 'n', 'd', 's', 0
	int  version;           // Version of the datastore's format
} nds_header_t;

/* --------------------------------------------
 * NDS shared data offsets
 * --------------------------------------------
 */

#define NDS_HEADER_START (0)
#define NDS_HEADER_SIZE (sizeof(nds_header_t))

#define NDS_ND_COUNTERS_START (NDS_HEADER_START + NDS_HEADER_SIZE)
#define NDS_ND_COUNTERS_SIZE (NDS_ND_COUNTER_COUNT * sizeof(uint64_t))
#define NDS_ND_COUNTERS(base_addr) ((uint64_t *)(base_addr + NDS_ND_COUNTERS_START))

// original NC counter section
#define NDS_NEURONCORE_COUNTERS_COUNT (NDS_NC_COUNTER_COUNT)
#define NDS_NEURONCORE_COUNTERS_START (NDS_ND_COUNTERS_START + NDS_ND_COUNTERS_SIZE)
#define NDS_NEURONCORE_COUNTERS_SIZE (NDS_NEURONCORE_COUNTERS_COUNT * NDS_MAX_NEURONCORE_COUNT * sizeof(uint64_t))
#define NDS_NEURONCORE_COUNTERS(base_addr, nc_index) ((uint64_t *)(base_addr + NDS_NEURONCORE_COUNTERS_START) + (nc_index * NDS_NEURONCORE_COUNTERS_COUNT))

// additional NC counter section at the end of all existing structures in the datastore (i.e. after NDS_PROCESS_EXT_INFO)
// NDS_PROCESS_EXT_INFO_START + NDS_PROCESS_EXT_INFO_SIZE = 44588 (hardcoded because it's easier than to move all the structs here and sizeof them)
#define NDS_EXT_NC_COUNTER_COUNT_OLD (65)
#define NDS_TOTAL_NC_COUNTER_COUNT_OLD (96)

#define NDS_EXT_NEURONCORE_COUNTERS_SIZE_OLD (NDS_EXT_NC_COUNTER_COUNT_OLD * NDS_MAX_NEURONCORE_COUNT * sizeof(uint64_t))
#define NDS_EXT_NEURONCORE_NC_DATA_SIZE_OLD	(NDS_TOTAL_NC_COUNTER_COUNT_OLD * NDS_EXT_MAX_NEURONCORE_COUNT * sizeof(uint64_t))
#define NDS_EXT_SECTION_SIZE_OLD (NDS_EXT_NEURONCORE_COUNTERS_SIZE_OLD + NDS_EXT_NEURONCORE_NC_DATA_SIZE_OLD)
#define NDS_EXT_OFFSET_OLD (44588)

#define NDS_EXT_ALIGNMENT (64)
#define NDS_ALIGN(v) ((v) + (-(v) & (NDS_EXT_ALIGNMENT - 1)))
#define NDS_EXT_OFFSET (NDS_ALIGN(NDS_EXT_OFFSET_OLD + NDS_EXT_SECTION_SIZE_OLD))

#define NDS_EXT_NEURONCORE_COUNTERS_COUNT (NDS_EXT_NC_COUNTER_COUNT) // number of extended counters
#define NDS_EXT_NEURONCORE_COUNTERS_START (NDS_EXT_OFFSET)
#define NDS_EXT_NEURONCORE_COUNTERS_SIZE (NDS_EXT_NC_COUNTER_COUNT * NDS_MAX_NEURONCORE_COUNT * sizeof(uint64_t))
#define NDS_EXT_NEURONCORE_COUNTERS(base_addr, nc_index) ((uint64_t *)(base_addr + NDS_EXT_NEURONCORE_COUNTERS_START) + (nc_index * NDS_EXT_NC_COUNTER_COUNT))

// additional NC data for extra Neuron Cores (12 extra sets which include all 95 counters + 1 for padding)
#define NDS_EXT_NEURONCORE_NC_DATA_PADDING (1) // 1 added as padding for 64 byte alignment per NC
#define NDS_EXT_NEURONCORE_NC_DATA_COUNT (NDS_TOTAL_NC_COUNTER_COUNT + NDS_EXT_NEURONCORE_NC_DATA_PADDING) // full set of counters (base + extended) + padding
#define NDS_EXT_NEURONCORE_NC_DATA_START (NDS_ALIGN(NDS_EXT_NEURONCORE_COUNTERS_START + NDS_EXT_NEURONCORE_COUNTERS_SIZE))
#define NDS_EXT_NEURONCORE_NC_DATA_SIZE (NDS_EXT_MAX_NEURONCORE_COUNT * NDS_EXT_NEURONCORE_NC_DATA_COUNT * sizeof(uint64_t))

#define NDS_EXT_NEURONCORE_NC_DATA(base_addr, nc_index) ((uint64_t *)(base_addr + NDS_EXT_NEURONCORE_NC_DATA_START) + (nc_index * NDS_EXT_NEURONCORE_NC_DATA_COUNT))

#endif  // NEURON_DRIVER_SHARED_H
